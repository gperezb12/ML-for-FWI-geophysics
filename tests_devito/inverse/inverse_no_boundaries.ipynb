{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fff1384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ef4cbb5-3124-495b-8502-ff623494e0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Configuración de dispositivo\n",
    "device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Función k verdadera en 2D (solo depende de y)\n",
    "def k_true_np(XY_np):\n",
    "    y = XY_np[:, 1:2]\n",
    "    epsilon = 125   # Steepness of the sigmoid\n",
    "    y0 = 500        # Midpoint of the sigmoid\n",
    "    k_true = 1.5 + 1.0 / (1 + np.exp(-(y - y0) / epsilon))\n",
    "    return k_true\n",
    "\n",
    "# 1) Generación de datos de entrenamiento\n",
    "N_train = 10000\n",
    "x_train = np.random.uniform(0,1000, (N_train, 1))\n",
    "y_train = np.random.uniform(0, 1000, (N_train, 1))\n",
    "XY_train = np.hstack([x_train, y_train])\n",
    "k_train_np = k_true_np(XY_train)\n",
    "\n",
    "XY_train_t = torch.tensor(XY_train, dtype=torch.float32, device=device)\n",
    "k_train_t  = torch.tensor(k_train_np, dtype=torch.float32, device=device)\n",
    "\n",
    "# 2) Definición de la red PINN_k_2D\n",
    "class PINN_k_2D(nn.Module):\n",
    "    def __init__(self, input_size=2, hidden_layers=12, hidden_units=128, act=nn.Tanh()):\n",
    "        super().__init__()\n",
    "        self.in_layer = nn.Linear(input_size, hidden_units)\n",
    "        self.hidden   = nn.ModuleList([\n",
    "            nn.Linear(hidden_units, hidden_units) \n",
    "            for _ in range(hidden_layers)\n",
    "        ])\n",
    "        self.act      = act\n",
    "        self.out      = nn.Linear(hidden_units, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.act(self.in_layer(x))\n",
    "        for layer in self.hidden:\n",
    "            h = self.act(layer(h))\n",
    "        return self.out(h)\n",
    "\n",
    "# 3) Instanciación y inicialización\n",
    "model_k2d = PINN_k_2D().to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.fill_(5.0)\n",
    "\n",
    "model_k2d.apply(init_weights)\n",
    "\n",
    "# 4) Entrenamiento con Adam + MSE\n",
    "optimizer = optim.Adam(model_k2d.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "epochs = 0\n",
    "for epoch in range(1, epochs + 1):\n",
    "    optimizer.zero_grad()\n",
    "    k_pred = model_k2d(XY_train_t)\n",
    "    loss = criterion(k_pred, k_train_t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"Epoch {epoch:4d}  loss = {loss.item():.4e}\")\n",
    "\n",
    "# 5) Graficar predicciones en malla 2D\n",
    "nx, ny = 100, 100\n",
    "x_vals = np.linspace(0, 1000, nx)\n",
    "y_vals = np.linspace(0, 1000, ny)\n",
    "X_mesh, Y_mesh = np.meshgrid(x_vals, y_vals)\n",
    "XY_mesh = np.vstack([X_mesh.ravel(), Y_mesh.ravel()]).T\n",
    "XY_mesh_t = torch.tensor(XY_mesh, dtype=torch.float32, device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    k_pred_mesh = model_k2d(XY_mesh_t).cpu().numpy().reshape(ny, nx)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "c = ax.pcolormesh(X_mesh, Y_mesh, k_pred_mesh, shading='auto')\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_title(\"Predicted k(x,y)\")\n",
    "plt.colorbar(c, ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff9e1afd-c33f-4d78-9d1f-4d25492dffbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n",
      "198657\n",
      ">>> FASE 1: Entrenamiento con Adam <<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adam:   0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Adam epoch     1] total_loss=1.1234e+04, data_loss_u_real=5.7656e+03, data_loss_u_imag=5.4619e+03, data_loss_k=6.2864e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adam:   0%|          | 18/10000 [00:16<2:32:51,  1.09it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[1;32m    <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=431'>432</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39msum\u001b[39m(p\u001b[39m.\u001b[39mnumel() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m model_u_real\u001b[39m.\u001b[39mparameters() \u001b[39mif\u001b[39;00m p\u001b[39m.\u001b[39mrequires_grad) )\n\u001b[1;32m    <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=433'>434</a>\u001b[0m w \u001b[39m=\u001b[39m \u001b[39m0.012\u001b[39m\n\u001b[0;32m--> <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=434'>435</a>\u001b[0m model_u_real,model_u_imag, model_k, adam_LOSS, LGFGS_LOSS \u001b[39m=\u001b[39m train_inverse_pinn_mixed(\n\u001b[1;32m    <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=435'>436</a>\u001b[0m         model_u_real,model_u_imag, model_k, w,\n\u001b[1;32m    <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=436'>437</a>\u001b[0m         X_int,\n\u001b[1;32m    <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=437'>438</a>\u001b[0m         X_data_img, u_data_img, X_data_real, u_data_real, X_data_c, u_data_c,\n\u001b[1;32m    <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=438'>439</a>\u001b[0m         adam_epochs\u001b[39m=\u001b[39;49m\u001b[39m10000\u001b[39;49m,\n\u001b[1;32m    <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=439'>440</a>\u001b[0m         lbfgs_iterations\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m,\n\u001b[1;32m    <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=440'>441</a>\u001b[0m         lr_adam\u001b[39m=\u001b[39;49m\u001b[39m1e-4\u001b[39;49m,\n\u001b[1;32m    <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=441'>442</a>\u001b[0m         lr_lbfgs\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m,\n\u001b[1;32m    <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=442'>443</a>\u001b[0m         lambda_bc\u001b[39m=\u001b[39;49m\u001b[39m5.0\u001b[39;49m, \n\u001b[1;32m    <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=443'>444</a>\u001b[0m         lambda_data\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m    <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=444'>445</a>\u001b[0m         plot_every\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=446'>447</a>\u001b[0m plot_solution_and_k(model_u_real, model_u_imag, model_k, \u001b[39m0\u001b[39m, folder\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfigs_inverse_mixed_final\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=287'>288</a>\u001b[0m \u001b[39m#pde_loss_real = loss_pde_inverse_real(modelU_real, modelK, X_int,w)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=288'>289</a>\u001b[0m \u001b[39m#pde_loss_imag = loss_pde_inverse_imag(modelU_imag, modelK, X_int,w)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=290'>291</a>\u001b[0m data_loss_val_u_real \u001b[39m=\u001b[39m loss_data_u_real(modelU_real, X_data_real, u_data_real)\n\u001b[0;32m--> <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=291'>292</a>\u001b[0m data_loss_val_u_imag \u001b[39m=\u001b[39m loss_data_u_imag(modelU_imag, X_data_img, u_data_img)\n\u001b[1;32m    <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=293'>294</a>\u001b[0m data_loss_val_k \u001b[39m=\u001b[39m loss_data_k(modelK, X_data_c, u_data_c)\n\u001b[1;32m    <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=294'>295</a>\u001b[0m \u001b[39m#bc_loss = loss_bc(modelU, X_data)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=295'>296</a>\u001b[0m \n\u001b[1;32m    <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=296'>297</a>\u001b[0m \u001b[39m# In your Adam training loop\u001b[39;00m\n",
      "\u001b[1;32m/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=195'>196</a>\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mloss_data_u_imag\u001b[39m(model, X_data, u_data):\n\u001b[1;32m    <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=196'>197</a>\u001b[0m     u_pred \u001b[39m=\u001b[39m model(X_data)\n\u001b[0;32m--> <a href='vscode-notebook-cell://m5cmml4xbzpcf2a.studio.us-east-1.sagemaker.aws/home/sagemaker-user/tdg/ML-for-FWI-geophysics/tests_devito/inverse/inverse_no_boundaries.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=197'>198</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mmean((u_pred \u001b[39m-\u001b[39;49m u_data)\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[0;32m~/.conda/envs/tdg/lib/python3.10/site-packages/torch/_tensor.py:39\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[39mif\u001b[39;00m has_torch_function(args):\n\u001b[1;32m     38\u001b[0m         \u001b[39mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# Configurar dispositivo CUDA\n",
    "device = torch.device('cpu' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "###############################################################################\n",
    "# 1. Clases y funciones base\n",
    "###############################################################################\n",
    "\n",
    "class MLP_u(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers, hidden_units, activation_function):\n",
    "        super(MLP_u, self).__init__()\n",
    "        self.linear_in = nn.Linear(input_size, hidden_units)\n",
    "        self.linear_out = nn.Linear(hidden_units, output_size)\n",
    "        self.layers = nn.ModuleList([nn.Linear(hidden_units, hidden_units) for _ in range(hidden_layers)])\n",
    "        self.act = activation_function\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.linear_in(x)\n",
    "        for layer in self.layers:\n",
    "            x = self.act(layer(x))\n",
    "        x = self.linear_out(x)\n",
    "        return x\n",
    "    \n",
    "class MLP_k(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers, hidden_units, activation_function):\n",
    "        super(MLP_k, self).__init__()\n",
    "        self.linear_in = nn.Linear(input_size, hidden_units)\n",
    "        self.linear_out = nn.Linear(hidden_units, output_size)\n",
    "        self.layers = nn.ModuleList([nn.Linear(hidden_units, hidden_units) for _ in range(hidden_layers)])\n",
    "        self.act = activation_function\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.linear_in(x)\n",
    "        for layer in self.layers:\n",
    "            x = self.act(layer(x))\n",
    "        x = self.linear_out(x)\n",
    "        return x\n",
    "\n",
    "def derivative(dy: torch.Tensor, x: torch.Tensor, order: int = 1) -> torch.Tensor:\n",
    "    for _ in range(order):\n",
    "        dy = torch.autograd.grad(\n",
    "            dy, x,\n",
    "            grad_outputs=torch.ones_like(dy),\n",
    "            create_graph=True,\n",
    "            retain_graph=True\n",
    "        )[0]\n",
    "    return dy\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.0)\n",
    "\n",
    "###############################################################################\n",
    "# 2. Generar datos (observados y de colocalizaciÃ³n)\n",
    "###############################################################################\n",
    "\n",
    "def generate_interior_data_points(device):\n",
    "    from generate_data_points import generate_interior_data, sample_interior_data\n",
    "\n",
    "    X_data_img_aux, u_data_img_aux = generate_interior_data('data/imag_part_0.0120Hz.csv','u')  # for raw data\n",
    "    X_data_img, u_data_img = sample_interior_data(X_data_img_aux, u_data_img_aux, num_samples=10000, device='cpu')\n",
    "\n",
    "    X_data_real_aux, u_data_real_aux = generate_interior_data('data/real_part_0.0120Hz.csv','u')  # for raw data\n",
    "    X_data_real, u_data_real = sample_interior_data(X_data_real_aux, u_data_real_aux, num_samples=10000, device='cpu')\n",
    "\n",
    "    X_data_c_aux, u_data_c_aux = generate_interior_data('data/velocity_model.csv','c')  # for raw data\n",
    "    X_data_c, u_data_c = sample_interior_data(X_data_c_aux, u_data_c_aux, num_samples=10000, device='cpu')\n",
    "\n",
    "\n",
    "    X_data_real = X_data_real.to(torch.float32)\n",
    "    u_data_real = u_data_real.to(torch.float32)\n",
    "    X_data_img = X_data_img.to(torch.float32)\n",
    "    u_data_img = u_data_img.to(torch.float32)\n",
    "    X_data_c = X_data_c.to(torch.float32)\n",
    "    u_data_c = u_data_c.to(torch.float32)\n",
    "    return X_data_img, u_data_img, X_data_real, u_data_real, X_data_c, u_data_c\n",
    "\n",
    "\n",
    "def generate_collocation_points(N_interior=2000, N_boundary=200):\n",
    "    \"\"\"\n",
    "    Genera puntos de entrenamiento: interior (para el residual de la PDE)\n",
    "    y frontera (para la condiciÃ³n de frontera u=0), en el dominio [-3,3]^2.\n",
    "\n",
    "    Args:\n",
    "        N_interior (int): NÃºmero de puntos interiores.\n",
    "        N_boundary (int): NÃºmero de puntos en la frontera (y=0).\n",
    "\n",
    "    Returns:\n",
    "        (X_int, X_bnd) en formato (torch.Tensor, torch.Tensor).\n",
    "    \"\"\"\n",
    "    # Puntos interiores en [-3,3]x[-3,3]\n",
    "    x_int = np.random.normal(loc=500.0, scale=250, size=(N_interior, 1))\n",
    "    y_int = 975 - np.random.exponential(scale=200, size=(N_interior, 1))\n",
    "\n",
    "    #y_int = np.clip(y_int, -100000, -0.01)  # fuerza a estar bajo el eje x\n",
    "\n",
    "    X_int = np.hstack((x_int, y_int))  # (N_interior,2)\n",
    "    X_int = torch.tensor(X_int, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "    # Puntos sobre la lÃ­nea y = 0 (condiciÃ³n de frontera)\n",
    "    x_bnd = np.random.normal(loc=500.0, scale=250, size=(N_boundary, 1))\n",
    "    y_bnd = np.full((N_boundary, 1), 975)\n",
    "\n",
    "    X_bnd = np.hstack((x_bnd, y_bnd))\n",
    "    X_bnd = torch.tensor(X_bnd, dtype=torch.float32, requires_grad=True)\n",
    "    \n",
    "    return X_int, X_bnd\n",
    "###############################################################################\n",
    "# 3. DefiniciÃ³n de las pÃ©rdidas para el problema inverso\n",
    "###############################################################################\n",
    "\n",
    "def loss_pde_inverse_real(model_u, model_k, X_int, w):\n",
    "    u = model_u(X_int)\n",
    "    c = model_k(X_int)\n",
    "\n",
    "    grads_u = derivative(u, X_int, order=1)\n",
    "    u_x = grads_u[:, 0:1]\n",
    "    u_y = grads_u[:, 1:2]\n",
    "\n",
    "    u_xx = derivative(u_x, X_int, order=1)[:, 0:1]\n",
    "    u_yy = derivative(u_y, X_int, order=1)[:, 1:2]\n",
    "\n",
    "    x = X_int[:, 0:1]\n",
    "    y = X_int[:, 1:2]\n",
    "    \n",
    "    sin = torch.sin\n",
    "    exp = torch.exp\n",
    "    cos = torch.cos\n",
    "    pi = torch.pi\n",
    "    sqrt = torch.sqrt\n",
    "    f0 = 0.010\n",
    "    t0 = 0\n",
    "    forcing = 2*w**2*exp(torch.tensor(-w**2/f0**2))*cos(torch.tensor(2*pi*t0*w))/(sqrt(torch.tensor(pi))*f0**3)\n",
    "\n",
    "    residual = (u_xx+u_yy) + (w/c)**2 - forcing\n",
    "    \n",
    "    return torch.mean(residual**2)\n",
    "\n",
    "def loss_pde_inverse_imag(model_u, model_k, X_int, w):\n",
    "    u = model_u(X_int)\n",
    "    c = model_k(X_int)\n",
    "\n",
    "    grads_u = derivative(u, X_int, order=1)\n",
    "    u_x = grads_u[:, 0:1]\n",
    "    u_y = grads_u[:, 1:2]\n",
    "\n",
    "    u_xx = derivative(u_x, X_int, order=1)[:, 0:1]\n",
    "    u_yy = derivative(u_y, X_int, order=1)[:, 1:2]\n",
    "\n",
    "    x = X_int[:, 0:1]\n",
    "    y = X_int[:, 1:2]\n",
    "    \n",
    "    sin = torch.sin\n",
    "    exp = torch.exp\n",
    "    cos = torch.cos\n",
    "    pi = torch.pi\n",
    "    sqrt = torch.sqrt\n",
    "    f0 = 0.010\n",
    "    t0 = 0\n",
    "    forcing = -2 * w**2 * exp(torch.tensor(-w**2 / f0**2)) * sin(torch.tensor(2 * pi * t0 * w)) / (sqrt(torch.tensor(pi)) * f0**3)\n",
    "\n",
    "    residual = (u_xx+u_yy) + (w/c)**2 - forcing\n",
    "    \n",
    "    return torch.mean(residual**2)\n",
    "\n",
    "\"\"\"\n",
    "def loss_bc(model, X_bnd, alpha=0.5, beta=10):\n",
    "    x = X_bnd[:, 0:1]  # Solo la coordenada x, ya que y = 0\n",
    "    u_true = torch.exp(-alpha * x**2)\n",
    "    u_pred = model(X_bnd)\n",
    "\n",
    "    return torch.mean((u_pred - u_true) ** 2)\n",
    "\"\"\"\n",
    "def loss_data_u_real(model, X_data, u_data):\n",
    "    u_pred = model(X_data)\n",
    "    return torch.mean((u_pred - u_data)**2)\n",
    "\n",
    "def loss_data_u_imag(model, X_data, u_data):\n",
    "    u_pred = model(X_data)\n",
    "    return torch.mean((u_pred - u_data)**2)\n",
    "\n",
    "def loss_data_k(model, X_data, k_data):\n",
    "    k_pred = model(X_data)\n",
    "    return torch.mean((k_pred - k_data)**2)\n",
    "\n",
    "###############################################################################\n",
    "# 4. FunciÃ³n para graficar la soluciÃ³n y k\n",
    "###############################################################################\n",
    "\n",
    "def plot_solution_and_k(modelU_real, modelU_imag, modelK, epoch, folder=\"figs_inverse_mixed\", n_points=150):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    x_vals = np.linspace(0, 1000, n_points)\n",
    "    y_vals = np.linspace(0, 1000, n_points)\n",
    "    X_mesh, Y_mesh = np.meshgrid(x_vals, y_vals)\n",
    "    XY_np = np.vstack([X_mesh.ravel(), Y_mesh.ravel()]).T\n",
    "    XY_torch = torch.tensor(XY_np, dtype=torch.float32, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        u_pred_real = modelU_real(XY_torch).cpu().numpy()\n",
    "        u_pred_imag = modelU_imag(XY_torch).cpu().numpy()\n",
    "\n",
    "        k_pred = modelK(XY_torch).cpu().numpy()\n",
    "    u_pred_real = u_pred_real.reshape(n_points, n_points)\n",
    "    u_pred_imag = u_pred_imag.reshape(n_points, n_points)\n",
    "\n",
    "    k_pred = k_pred.reshape(n_points, n_points)\n",
    "\n",
    "\n",
    "\n",
    "    # Create a 2D figure with 4 subplots\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    \"\"\"\n",
    "    vmin = u_pred.min()\n",
    "    vmax = u_pred.max()\n",
    "    norm1 = colors.TwoSlopeNorm(vmin=vmin, vcenter=0.0, vmax=vmax)\n",
    "\n",
    "    vmin = u_true.min()\n",
    "    vmax = u_true.max()\n",
    "    norm2 = colors.TwoSlopeNorm(vmin=vmin, vcenter=0.0, vmax=vmax)\n",
    "    \"\"\"\n",
    "    # 2D plot for PINN u\n",
    "    ax1 = fig.add_subplot(3, 1, 1)\n",
    "    im1 = ax1.pcolormesh(X_mesh, Y_mesh, u_pred_real, cmap='seismic', shading='auto')\n",
    "    ax1.set_title(f\"PINN u (epoch {epoch})\")\n",
    "    fig.colorbar(im1, ax=ax1)\n",
    "    \n",
    "    # 2D plot for Analytic u\n",
    "    ax2 = fig.add_subplot(3, 1, 2)\n",
    "    im2 = ax2.pcolormesh(X_mesh, Y_mesh, u_pred_imag, cmap='seismic', shading='auto')\n",
    "    ax2.set_title(\"Analytic u\")\n",
    "    fig.colorbar(im2, ax=ax2)\n",
    "    \n",
    "    # 2D plot for Analytic k\n",
    "    ax3 = fig.add_subplot(3, 1, 3)\n",
    "    im3 = ax3.pcolormesh(X_mesh, Y_mesh, k_pred, cmap='GnBu', shading='auto')\n",
    "    ax3.set_title(\"Analytic k\")\n",
    "    fig.colorbar(im3, ax=ax3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(folder, f\"solution_epoch_{epoch}.png\"))\n",
    "    plt.close(fig)\n",
    "\n",
    "###############################################################################\n",
    "# 5. Entrenamiento\n",
    "###############################################################################\n",
    "\n",
    "def train_inverse_pinn_mixed(\n",
    "    modelU_real, modelU_imag, modelK, w,\n",
    "    X_int,\n",
    "    X_data_img, u_data_img, X_data_real, u_data_real, X_data_c, u_data_c,\n",
    "    adam_epochs=10000,\n",
    "    lbfgs_iterations=500,\n",
    "    lr_adam=1e-4,\n",
    "    lr_lbfgs=0.5,\n",
    "    lambda_bc=5.0, \n",
    "    lambda_data=1.0,\n",
    "    plot_every=1000\n",
    "):\n",
    "    # Lists to store losses\n",
    "    adam_loss_history = []\n",
    "    lbfgs_loss_history = []\n",
    "\n",
    "    optimizer_adam = torch.optim.Adam(list(modelU_real.parameters()) + list(modelU_imag.parameters()) + list(modelK.parameters()), lr=lr_adam)\n",
    "    print(\">>> FASE 1: Entrenamiento con Adam <<<\")\n",
    "    for epoch in tqdm(range(1, adam_epochs+1), desc=\"Adam\"):\n",
    "        optimizer_adam.zero_grad()\n",
    "\n",
    "        #pde_loss_real = loss_pde_inverse_real(modelU_real, modelK, X_int,w)\n",
    "        #pde_loss_imag = loss_pde_inverse_imag(modelU_imag, modelK, X_int,w)\n",
    "\n",
    "        data_loss_val_u_real = loss_data_u_real(modelU_real, X_data_real, u_data_real)\n",
    "        data_loss_val_u_imag = loss_data_u_imag(modelU_imag, X_data_img, u_data_img)\n",
    "\n",
    "        data_loss_val_k = loss_data_k(modelK, X_data_c, u_data_c)\n",
    "        #bc_loss = loss_bc(modelU, X_data)\n",
    "\n",
    "        # In your Adam training loop\n",
    "        total_loss = (\n",
    "                    lambda_data * data_loss_val_u_real + \n",
    "                    lambda_data * data_loss_val_k + \n",
    "                    lambda_data * data_loss_val_u_imag)\n",
    "\n",
    "        # Store the loss values before backward if you need them for printing\n",
    "        loss_values = {\n",
    "            'total_loss': total_loss.item(),\n",
    "            'data_loss_u_real': data_loss_val_u_real.item(),\n",
    "            'data_loss_u_imag': data_loss_val_u_imag.item(),\n",
    "            'data_loss_k': data_loss_val_k.item()\n",
    "        }\n",
    "        \n",
    "        total_loss.backward(retain_graph=True)\n",
    "        optimizer_adam.step()\n",
    "\n",
    "        # Now use loss_values for printing\n",
    "        if epoch % plot_every == 0 or epoch == 1 or epoch == adam_epochs:\n",
    "            adam_loss_history.append(loss_values['total_loss'])\n",
    "            print(f\"  [Adam epoch {epoch:5d}] total_loss={loss_values['total_loss']:.4e}, \"\n",
    "                f\"data_loss_u_real={loss_values['data_loss_u_real']:.4e}, \"\n",
    "                f\"data_loss_u_imag={loss_values['data_loss_u_imag']:.4e}, \"\n",
    "                f\"data_loss_k={loss_values['data_loss_k']:.4e}\")\n",
    "\n",
    "\n",
    "            plot_solution_and_k(modelU_real,modelU_imag, modelK, epoch, folder=f\"exp1/figs_inverse_w={w}\")\n",
    "    \"\"\"\n",
    "    print(\">>> FASE 2: Entrenamiento con L-BFGS <<<\")\n",
    "    optimizer_lbfgs = torch.optim.LBFGS(\n",
    "        list(modelU_real.parameters()) + list(modelU_imag.parameters()) + list(modelK.parameters()),\n",
    "        lr=lr_lbfgs,\n",
    "        max_iter=lbfgs_iterations,\n",
    "        history_size=100\n",
    "    )\n",
    "\n",
    "    iteration_lbfgs = [0]\n",
    "    def closure():\n",
    "        optimizer_lbfgs.zero_grad()\n",
    "\n",
    "        pde_loss_real = loss_pde_inverse_real(modelU_real, modelK, X_int,w)\n",
    "        pde_loss_imag = loss_pde_inverse_imag(modelU_imag, modelK, X_int,w)\n",
    "\n",
    "        data_loss_val_u_real = loss_data_u_real(modelU_real, X_data_real, u_data_real)\n",
    "        data_loss_val_u_imag = loss_data_u_imag(modelU_imag, X_data_img, u_data_img)\n",
    "\n",
    "        data_loss_val_k = loss_data_k(modelK, X_data_c, u_data_c)\n",
    "        #bc_loss = loss_bc(modelU, X_data)\n",
    "\n",
    "        total_loss = pde_loss_real + pde_loss_imag + lambda_data * data_loss_val_u_real + lambda_data * data_loss_val_k + lambda_bc * data_loss_val_u_imag\n",
    "\n",
    "        total_loss.backward()\n",
    "        return total_loss\n",
    "\n",
    "    for i in tqdm(range(1, lbfgs_iterations+1)):\n",
    "        iteration_lbfgs[0] += 1\n",
    "\n",
    "        pde_loss_real = loss_pde_inverse_real(modelU_real, modelK, X_int,w).item\n",
    "        pde_loss_imag = loss_pde_inverse_imag(modelU_imag, modelK, X_int,w).item\n",
    "\n",
    "        data_loss_val_u_real = loss_data_u_real(modelU_real, X_data_real, u_data_real).item\n",
    "        data_loss_val_u_imag = loss_data_u_imag(modelU_imag, X_data_img, u_data_img).item\n",
    "\n",
    "        data_loss_val_k = loss_data_k(modelK, X_data_c, u_data_c).item\n",
    "        #bc_loss = loss_bc(modelU, X_data)\n",
    "\n",
    "        total_loss = pde_loss_real + pde_loss_imag + lambda_data * data_loss_val_u_real + lambda_data * data_loss_val_k + lambda_bc * data_loss_val_u_imag\n",
    "\n",
    "\n",
    "        if (i+1) % 50 == 0 or (i+1) == lbfgs_iterations:\n",
    "            lbfgs_loss_history.append(total_loss)\n",
    "            print(f\"  [Adam epoch {epoch:5d}] total_loss={total_loss.item():.4e}, \"\n",
    "                f\"pde_loss_real={pde_loss_real.item():.4e}, \"\n",
    "                f\"pde_loss_imag={pde_loss_imag.item():.4e}, \"\n",
    "                f\"data_loss_u_real={data_loss_val_u_real.item():.4e}, \"\n",
    "                f\"data_loss_u_imag={data_loss_val_u_imag.item():.4e}, \"\n",
    "                f\"data_loss_k={data_loss_val_k.item():.4e}\")\n",
    "            \n",
    "            plot_solution_and_k(modelU_real, modelU_imag, modelK, adam_epochs + i + 1, folder=f\"exp1/figs_inverse_w={w}\")\n",
    "    \"\"\"\n",
    "    return modelU_real, modelU_imag, modelK, adam_loss_history, lbfgs_loss_history\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 6. EjecuciÃ³n principal\n",
    "###############################################################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    set_seed(32)\n",
    "\n",
    "    X_int, X_bnd = generate_collocation_points(N_interior=10000, N_boundary=5000)\n",
    "    X_data_img, u_data_img, X_data_real, u_data_real, X_data_c, u_data_c = generate_interior_data_points(device='cpu')\n",
    "\n",
    "    model_u_real = MLP_u(\n",
    "        input_size=2,\n",
    "        output_size=1,\n",
    "        hidden_layers= 12,\n",
    "        hidden_units=128,\n",
    "        activation_function=nn.Tanh()\n",
    "    ).to(device)\n",
    "    model_u_real.apply(init_weights)\n",
    "\n",
    "    model_u_imag = MLP_u(\n",
    "        input_size=2,\n",
    "        output_size=1,\n",
    "        hidden_layers= 12,\n",
    "        hidden_units=128,\n",
    "        activation_function=nn.Tanh()\n",
    "    ).to(device)\n",
    "    model_u_imag.apply(init_weights)\n",
    "\n",
    "    model_k = MLP_k(\n",
    "        input_size=2,\n",
    "        output_size=1,\n",
    "        hidden_layers= 12,\n",
    "        hidden_units=128,\n",
    "        activation_function=nn.Tanh()\n",
    "    ).to(device)\n",
    "    model_k.apply(init_weights)\n",
    "\n",
    "    # 2) Copia la parte común (entrada + capas ocultas)\n",
    "    \"\"\"\n",
    "    model_k.linear_in.load_state_dict(model_k2d.in_layer.state_dict())\n",
    "    for layer_uvk, layer_k2d in zip(model_k.layers, model_k2d.hidden):\n",
    "        layer_uvk.load_state_dict(layer_k2d.state_dict())\n",
    "    \n",
    "    # 3) “Warm-start” del canal k en linear_out\n",
    "    with torch.no_grad():\n",
    "        # Copiando la fila 1 de los pesos (que sí es [H])\n",
    "        model_k.linear_out.weight.data[0] = model_k2d.out.weight.data[0]\n",
    "        # Copiando el bias escalar:\n",
    "        model_k.linear_out.bias.data[0] = model_k2d.out.bias.data[0]\n",
    "\n",
    "    plot_solution_and_k(model_u_real, model_u_imag, model_k, 0, folder=\"figs_inverse\")\n",
    "    \"\"\"\n",
    "    print(sum(p.numel() for p in model_u_real.parameters() if p.requires_grad) )\n",
    "\n",
    "    w = 0.012\n",
    "    model_u_real,model_u_imag, model_k, adam_LOSS, LGFGS_LOSS = train_inverse_pinn_mixed(\n",
    "            model_u_real,model_u_imag, model_k, w,\n",
    "            X_int,\n",
    "            X_data_img, u_data_img, X_data_real, u_data_real, X_data_c, u_data_c,\n",
    "            adam_epochs=10000,\n",
    "            lbfgs_iterations=500,\n",
    "            lr_adam=1e-4,\n",
    "            lr_lbfgs=0.5,\n",
    "            lambda_bc=5.0, \n",
    "            lambda_data=1.0,\n",
    "            plot_every=500)\n",
    "\n",
    "    plot_solution_and_k(model_u_real, model_u_imag, model_k, 0, folder=\"figs_inverse_mixed_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9908182c-bc7f-47bf-8c37-cb1cb1883fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_error_analytic(model_u, model_k, n_points=200, device='cpu'):\n",
    "    \"\"\"\n",
    "    Computes the relative percentage error between model predictions and ground truth for u and k.\n",
    "    \n",
    "    Args:\n",
    "        model_u (torch.nn.Module): Trained model predicting u(x, y).\n",
    "        model_k (torch.nn.Module): Trained model predicting k(x, y).\n",
    "        alpha (float): Parameter in the analytic solution of u.\n",
    "        beta (float): Parameter in the analytic solution of u.\n",
    "        epsilon (float): Parameter in the analytic solution of k.\n",
    "        n_points (int): Number of grid points in each dimension.\n",
    "        device (str): 'cpu' or 'cuda'.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of relative percentage errors for u and k: (rel_error_u, rel_error_k)\n",
    "    \"\"\"\n",
    "    alpha = 0.5\n",
    "    beta = 10\n",
    "    epsilon = 0.2\n",
    "    # Crear la malla\n",
    "    x = np.linspace(-3, 3, n_points)\n",
    "    y = np.linspace(-3, 0, n_points)\n",
    "    X, Y = np.meshgrid(x, y, indexing='ij')\n",
    "    XY_np = np.stack([X.flatten(), Y.flatten()], axis=1)\n",
    "\n",
    "    # Convertir a tensor para usar en los modelos\n",
    "    XY_tensor = torch.tensor(XY_np, dtype=torch.float32, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        u_pred = model_u(XY_tensor).cpu().numpy().reshape(n_points, n_points)\n",
    "        k_pred = model_k(XY_tensor).cpu().numpy().reshape(n_points, n_points)\n",
    "\n",
    "    # Soluciones analíticas\n",
    "    u_true = np.exp(-alpha * (X**2 + Y**2)) * np.cos(beta * Y)\n",
    "    k_true = 1 + 2 / (1 + np.exp(-(Y+1) / epsilon))\n",
    "\n",
    "    # Evitar división por cero\n",
    "    u_true_safe = np.where(np.abs(u_true) < 1e-8, 1e-8, u_true)\n",
    "    k_true_safe = np.where(np.abs(k_true) < 1e-8, 1e-8, k_true)\n",
    "\n",
    "    # Error relativo porcentual promedio\n",
    "    rel_err_u = np.mean(np.abs((u_pred - u_true) / u_true_safe)) * 100\n",
    "    rel_err_k = np.mean(np.abs((k_pred - k_true) / k_true_safe)) * 100\n",
    "\n",
    "    return rel_err_u, rel_err_k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a91411d4-33d1-47d7-a2d0-48ea9914bc9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75102.31989480945, 25.47353456360522)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_error_analytic(model_u, model_k, n_points=200, device='cpu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tdg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
